{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekpy import analysis\n",
    "import numpy as np\n",
    "import scipy.integrate as it\n",
    "from scipy.signal import find_peaks, savgol_filter, peak_widths\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_delay</th>\n",
       "      <th>pulse_delay</th>\n",
       "      <th>freq</th>\n",
       "      <th>voltage</th>\n",
       "      <th>capacitor_area</th>\n",
       "      <th>thickness</th>\n",
       "      <th>permittivity</th>\n",
       "      <th>amplification</th>\n",
       "      <th>format</th>\n",
       "      <th>type</th>\n",
       "      <th>points</th>\n",
       "      <th>count</th>\n",
       "      <th>x_increment</th>\n",
       "      <th>x_origin</th>\n",
       "      <th>x_reference</th>\n",
       "      <th>y_increment</th>\n",
       "      <th>y_origin</th>\n",
       "      <th>y_reference</th>\n",
       "      <th>trial</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>995</td>\n",
       "      <td>1</td>\n",
       "      <td>4.720000e-07</td>\n",
       "      <td>2.710505e-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fe_pv__0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>995</td>\n",
       "      <td>1</td>\n",
       "      <td>4.720000e-07</td>\n",
       "      <td>2.710505e-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fe_pv__1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>995</td>\n",
       "      <td>1</td>\n",
       "      <td>4.720000e-07</td>\n",
       "      <td>2.710505e-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fe_pv__2.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>995</td>\n",
       "      <td>1</td>\n",
       "      <td>4.720000e-07</td>\n",
       "      <td>2.710505e-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fe_pv__3.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>995</td>\n",
       "      <td>1</td>\n",
       "      <td>4.720000e-07</td>\n",
       "      <td>2.710505e-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fe_pv__4.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>995</td>\n",
       "      <td>1</td>\n",
       "      <td>4.720000e-07</td>\n",
       "      <td>2.710505e-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fe_pv__5.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_delay  pulse_delay  freq  voltage  capacitor_area     thickness  \\\n",
       "0        0.00005     0.000005    10        1    4.000000e-08  1.000000e-08   \n",
       "1        0.00005     0.000005    10        1    4.000000e-08  1.000000e-08   \n",
       "2        0.00005     0.000005    10        1    4.000000e-08  1.000000e-08   \n",
       "3        0.00005     0.000005    10        1    4.000000e-08  1.000000e-08   \n",
       "4        0.00005     0.000005    10        1    4.000000e-08  1.000000e-08   \n",
       "5        0.00005     0.000005    10        1    4.000000e-08  1.000000e-08   \n",
       "\n",
       "   permittivity  amplification  format  type  points  count   x_increment  \\\n",
       "0            30              8       0     0     995      1  4.720000e-07   \n",
       "1            30              8       0     0     995      1  4.720000e-07   \n",
       "2            30              8       0     0     995      1  4.720000e-07   \n",
       "3            30              8       0     0     995      1  4.720000e-07   \n",
       "4            30              8       0     0     995      1  4.720000e-07   \n",
       "5            30              8       0     0     995      1  4.720000e-07   \n",
       "\n",
       "       x_origin  x_reference  y_increment  y_origin  y_reference  trial  \\\n",
       "0  2.710505e-20            0      0.01005       0.0            0      0   \n",
       "1  2.710505e-20            0      0.01005       0.0            0      0   \n",
       "2  2.710505e-20            0      0.01005       0.0            0      0   \n",
       "3  2.710505e-20            0      0.01005       0.0            0      0   \n",
       "4  2.710505e-20            0      0.01005       0.0            0      0   \n",
       "5  2.710505e-20            0      0.01005       0.0            0      0   \n",
       "\n",
       "       filename  \n",
       "0  fe_pv__0.csv  \n",
       "1  fe_pv__1.csv  \n",
       "2  fe_pv__2.csv  \n",
       "3  fe_pv__3.csv  \n",
       "4  fe_pv__4.csv  \n",
       "5  fe_pv__5.csv  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "dset = analysis.load_Dataset('./newsampleworksradiant')\n",
    "\n",
    "# print dset, parsable collection of meta data which holds pointers to the real data files\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dset.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = dset.query(\"voltage == 1\").get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = dset.select_index(0).get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'initial_delay': {5e-05},\n",
       " 'pulse_delay': {5e-06},\n",
       " 'freq': {10},\n",
       " 'voltage': {1},\n",
       " 'capacitor_area': {4e-08},\n",
       " 'thickness': {1e-08},\n",
       " 'permittivity': {30},\n",
       " 'amplification': {8},\n",
       " 'format': {0},\n",
       " 'type': {0},\n",
       " 'points': {995},\n",
       " 'count': {1},\n",
       " 'x_increment': {4.72e-07},\n",
       " 'x_origin': {2.71050543e-20},\n",
       " 'x_reference': {0},\n",
       " 'y_increment': {0.01005025},\n",
       " 'y_origin': {0.0},\n",
       " 'y_reference': {0},\n",
       " 'trial': {0}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_v', 'wfm_v', 'time_c', 'wfm_c']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.data_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.plot(x='time_v', y='wfm_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.plot(x='time_c', y='wfm_c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use data.definition (no parenthesis) to get all the meta data associated with the exp for all trials in the dset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may need to normalize the data for the wfm c to 0, aka shift it correspondingly. not sure why since it should be doing that but I will have to think about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data2) #this is already a numpy array lets fucking gooo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['time_v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0].plot(x='time_v', y='wfm_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_q_wfm(data_dict) -> 'dict':\n",
    "    wfm_q = it.cumulative_trapezoid(data_dict['wfm_c'], data_dict['time_c'], initial=0) \n",
    "    data_dict['wfm_q'] = wfm_q\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_q_wfm_wrong(data_dict) -> 'dict':\n",
    "    wfm_q = it.cumulative_trapezoid(data_dict['wfm_v'], data_dict['time_v'], initial=0) \n",
    "    data_dict['wfm_q_wrong'] = wfm_q\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drift_correct_q(data_dict)-> 'dict':\n",
    "    slope = (data_dict['wfm_q'][-1] - data_dict['wfm_q'][0])/(data_dict['time_c'][-1] - data_dict['time_c'][0])\n",
    "    wfm_q_drift_corrected = []\n",
    "    for i in range(len(data_dict['wfm_q'])):\n",
    "        wfm_q_drift_corrected.append(data_dict['wfm_q'][i]-(slope*data_dict['time_c'][i]))\n",
    "    data_dict['wfm_q'] = wfm_q_drift_corrected\n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwwwww = data2.apply(generate_q_wfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwwwww.plot(x='time_c', y='wfm_q') #IT WORKS!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwwwww2 = newwwwww.apply(drift_correct_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newwwwww2.plot(x='time_c', y='wfm_q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = data2.apply(generate_q_wfm_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong.plot(x='time_v', y='wfm_q_wrong')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to convert this to polarization plot vs voltage. We are using the derivative of the waveform to essentially find out when the wavefoprm starts and ends\n",
    "1. First take derivative of wfm\n",
    "2. Then find points where it starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(data_dict)->'dict':\n",
    "    wfm_int = np.gradient(data_dict['wfm_v'], data_dict['time_v'])\n",
    "    #add smoothing?\n",
    "    wfm_int_smooth = savgol_filter(wfm_int, 51, 3)\n",
    "    #normalize values to 1\n",
    "    wfm_int_smooth_norm =  2 * ((wfm_int_smooth - np.min(wfm_int_smooth)) / (np.max(wfm_int_smooth) - np.min(wfm_int_smooth))) - 1\n",
    "    data_dict['wfm_int'] = wfm_int_smooth_norm\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong2 = wrong.apply(derivative) #bruh why did i call it wfm_int its not an integral lmfaooo, wrong 2 is useless in the grandscheme of things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong2.plot(x='time_v', y='wfm_int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE A FUNCTION CALLED VISUALIZE ANALYSIS THAT DOES EACH STEP OF THE PROCESS AND PLOTS SEQUENTIALLY WITH APPROPIATE CAPTIONS (TITLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW METHOD, USE FINDPEAKS AND FINDTROUGHS (FIND PEAKS OF INVERTED DATASET) AND THAT IS EQUAL TO HALF OF THE TOTAL PULSE LENGTH AND JUST USE THAT TO FIND THE START AND END!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peaks_troughs_index(data_dict)->'dict':\n",
    "    arr = data_dict['wfm_v']\n",
    "    arr_normalized = 2 * ((arr - np.min(arr)) / (np.max(arr) - np.min(arr))) - 1\n",
    "    peaks, _ = find_peaks(arr_normalized, height=0.8)\n",
    "    troughs, _ = find_peaks(-1*arr_normalized, height=0.8)\n",
    "    all_peaks = np.concatenate((peaks, troughs), axis=0)\n",
    "    #results_full = peak_widths(arr_normalized, peaks, rel_height=1)\n",
    "    #data_dict['results_full'] = results_full\n",
    "    data_dict['peaks'] = np.sort(all_peaks)\n",
    "    return data_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong3 = wrong2.apply(find_peaks_troughs_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing this here\n",
    "wrong3 = newwwwww2.apply(find_peaks_troughs_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong3['peaks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong3.plot(x='time_v', y='wfm_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_and_end_pulse(data_dict)->'dict':\n",
    "    x = data_dict['peaks']\n",
    "    counter = 0\n",
    "    green_points = []\n",
    "    while counter <(len(x)):\n",
    "        half_pulse_len = x[counter+1] - x[counter]\n",
    "        quarter_pulse_len = half_pulse_len/2\n",
    "        start_of_pulse = x[counter] - quarter_pulse_len\n",
    "        end_of_pulse = x[counter+1] + quarter_pulse_len\n",
    "        green_points.append(int(start_of_pulse))\n",
    "        green_points.append(int(end_of_pulse))\n",
    "        counter +=2\n",
    "    data_dict['start_and_end_pulse'] = green_points\n",
    "    return data_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong4 = wrong3.apply(start_and_end_pulse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong4['start_and_end_pulse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong4.data_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = wrong3['peaks']\n",
    "print(x)\n",
    "green_points = []\n",
    "counter = 0\n",
    "while counter <(len(x)):\n",
    "    half_pulse_len = x[counter+1] - x[counter]\n",
    "    quarter_pulse_len = half_pulse_len/2\n",
    "    start_of_pulse = x[counter] - quarter_pulse_len\n",
    "    end_of_pulse = x[counter+1] + quarter_pulse_len\n",
    "    green_points.append(int(start_of_pulse))\n",
    "    green_points.append(int(end_of_pulse))\n",
    "    counter +=2\n",
    "print(green_points)\n",
    "#witdthss = wrong3['results_full']\n",
    "#widthsfixed = (np.array([109.5, 222. , 222. , 108. ]), np.array([-0.02020202, -1.        , -1.        , -0.01010101]), np.array([103., 265., 604., 879.]), np.array([212.5, 487. , 826. , 987. ]))\n",
    "plt.scatter(wrong3['time_v'][x], wrong3['wfm_v'][x], color='red') #need to use a hieght\n",
    "#plt.hlines(*widthsfixed[1:], color='C2')\n",
    "plt.scatter(wrong3['time_v'][green_points], wrong3['wfm_v'][green_points], color='green')\n",
    "plt.plot(wrong3['time_v'], wrong3['wfm_v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wrong3['time_v'][green_points[0]:green_points[1]+1], wrong3['wfm_v'][green_points[0]:green_points[1]+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong4.data_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = wrong4['wfm_v'][wrong4['start_and_end_pulse'][0]:wrong4['start_and_end_pulse'][1]+1]\n",
    "y1 = wrong4['wfm_q'][wrong4['start_and_end_pulse'][0]:wrong4['start_and_end_pulse'][1]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = wrong4['wfm_v'][wrong4['start_and_end_pulse'][2]:wrong4['start_and_end_pulse'][3]+1]\n",
    "y2 = wrong4['wfm_q_wrong'][wrong4['start_and_end_pulse'][2]:wrong4['start_and_end_pulse'][3]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data2.data_keys)\n",
    "print(wrong.data_keys)\n",
    "print(wrong2.data_keys)\n",
    "print(wrong3.data_keys)\n",
    "print(wrong4.data_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong4.to_ekpdat('./test69') #saves data when ur working, good to know to add lmao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here I will make a helper funciton that takes in a doc string and returns what funciton it appends based on the format\n",
    "\"\"\"\n",
    "\n",
    "def get_function_doc_append(doc_string):\n",
    "    \"\"\"\n",
    "    Helper function which takes in an appropiately formatted string and scans it for the appended value. See use_analysis_file for more\n",
    "    information\n",
    "    \"\"\"\n",
    "    ending_index_of_match = doc_string.find(\"MODIFIES:\") + len(\"MODIFIES:\")\n",
    "    func_name_appended = doc_string[ending_index_of_match:].strip()\n",
    "    return func_name_appended\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import getmembers, isfunction, getdoc\n",
    "from importlib import import_module\n",
    "from ekpy.analysis.core import Data, Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "def use_analysis_file(module, data, saveall=False, path=None):\n",
    "    \"\"\"\n",
    "    Reads correctly formatted analysis file and performs all functions in sequential order and returns the final mutated Data. Only want it to return the final\n",
    "    mutated data alongside the original unless saveall=True\n",
    "\n",
    "    So because of overriding cases where a func overrides something by say data_dict['voltage'] = new_voltage but data_dict['voltage'] already existed we\n",
    "    have data saver to save the day!\n",
    "\n",
    "    Args:\n",
    "        module (str): the name of the analysis file which must be in the same directory.\n",
    "        data (ekpy.data): The data to use the analysis file on.\n",
    "        saveall (Boolean): If set to true it saves each intermediate step to a file\n",
    "        path (str): if savell is true you must set a path where to save the intermediate steps. Usually the path where you pulled the dset from.\n",
    "\n",
    "    Returns:\n",
    "        data (ekpy.data): The modified data.\n",
    "        data_saver (dict): A Dictionary containing all the intermediate steps of the data. (optional)\n",
    "    \"\"\"\n",
    "    module = import_module(module)\n",
    "    functions_list = module.__all__\n",
    "    data_saver = {'data0': data,}\n",
    "    funcs_modified = ['original',]\n",
    "    for i, name in enumerate(functions_list):\n",
    "        func = getattr(module, name)\n",
    "        func_doc_str = getdoc(func)\n",
    "        func_appended = get_function_doc_append(func_doc_str)\n",
    "        funcs_modified.append(func_appended)\n",
    "        key_name = f\"data{i + 1}\"\n",
    "        data_saver[key_name] = data.apply(func)\n",
    "        data = data_saver[key_name]\n",
    "    original_data = data_saver['data0'].to_dict()\n",
    "    last_data_added = data[data.data_keys[-1]]\n",
    "    original_data[0]['data'][data.data_keys[-1]] = last_data_added\n",
    "    data_out = Data(original_data)\n",
    "    if saveall:\n",
    "        if path is None:\n",
    "            print(\"Warning creating a directory since a path was not given\")\n",
    "            path = './'\n",
    "        path = path + 'data_saver0'\n",
    "        iterator = 1\n",
    "        while os.path.exists(path):\n",
    "            if iterator > 1000:\n",
    "                raise ValueError(\"Dog make a new directory. you have over 1000 folders here or something messed up\")\n",
    "            path = list(path)\n",
    "            path[-1] = str(iterator)\n",
    "            path = \"\".join(path)\n",
    "            iterator += 1\n",
    "        os.mkdir(path)\n",
    "        print(\"Folder %s created!\" % path)\n",
    "        print(funcs_modified)\n",
    "        meta_data_saver = pd.DataFrame({\n",
    "                            'funcs_modified': funcs_modified,\n",
    "                            'filename': list(data_saver.keys())}\n",
    "            )\n",
    "        meta_data_saver.to_csv(path + '/meta_deta', index=False)\n",
    "        #dset = Dataset(path, meta_data_saver)\n",
    "        #dset.to_ekpds(path)\n",
    "        for keys in data_saver:\n",
    "            data_saver[keys].to_ekpdat(path +f'\\\\{keys}')\n",
    "        return data_out, data_saver\n",
    "    else:\n",
    "        return data_out, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data2.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['time_v', 'wfm_v', 'time_c', 'wfm_c', 'wfm_q_wrong'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3[0]['data'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_ekpdat('testnew/yay') #saves modifed data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "betee, backup = use_analysis_file('analysisfile', data2, False, './testnew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning creating a directory since a path was not given\n",
      "Folder ./data_saver1 created!\n",
      "['original', 'wfm_q', 'wfm_q_wrong']\n"
     ]
    }
   ],
   "source": [
    "betee, backup = use_analysis_file('analysisfile', data2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_v', 'wfm_v', 'time_c', 'wfm_c', 'wfm_q_wrong', 'wfm_q']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betee.data_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bbb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbackup\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#can use list to just get the keys as a list\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "bbb = list(backup) #can use list to just get the keys as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data0', 'data1', 'data2']\n"
     ]
    }
   ],
   "source": [
    "print(bbb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_v', 'wfm_v', 'time_c', 'wfm_c', 'wfm_q_wrong', 'wfm_q']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backup['data0'].data_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup['data1'].data_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_v', 'wfm_v', 'time_c', 'wfm_c', 'wfm_q_wrong']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.data_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_list = getmembers(analysisfile, isfunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
